{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Workshop - Build and Deploy Application to Amazon Fargate \u00b6 Introduction \u00b6 This workshop is designed to enable engineers to get some hands-on experience using AWS CI/CD tools to build pipelines for ECS workloads. The workshop consists of a number of lab modules, each designed to demonstrate a CI/CD pattern. You will be using AWS services like AWS CodePipeline, AWS CodeCommit, AWS CodeBuild, AWS CloudFormation, and AWS CodeDeploy. Background \u00b6 The Spring PetClinic sample application is designed to show how the Spring application framework can be used to build simple, but powerful database-oriented applications. It uses AWS RDS (MySQL) at the backend and it will demonstrate the use of Spring's core functionality. The Spring Framework is a collection of small, well-focused, loosely coupled Java frameworks that can be used independently or collectively to build industrial strength applications of many different types. Contributors \u00b6 Irshad A Buchh, Amazon Web Services Mike Rizzo, Amazon Web Services","title":"Workshop - Build and Deploy Application to Amazon Fargate"},{"location":"#workshop-build-and-deploy-application-to-amazon-fargate","text":"","title":"Workshop - Build and Deploy Application to Amazon Fargate"},{"location":"#introduction","text":"This workshop is designed to enable engineers to get some hands-on experience using AWS CI/CD tools to build pipelines for ECS workloads. The workshop consists of a number of lab modules, each designed to demonstrate a CI/CD pattern. You will be using AWS services like AWS CodePipeline, AWS CodeCommit, AWS CodeBuild, AWS CloudFormation, and AWS CodeDeploy.","title":"Introduction"},{"location":"#background","text":"The Spring PetClinic sample application is designed to show how the Spring application framework can be used to build simple, but powerful database-oriented applications. It uses AWS RDS (MySQL) at the backend and it will demonstrate the use of Spring's core functionality. The Spring Framework is a collection of small, well-focused, loosely coupled Java frameworks that can be used independently or collectively to build industrial strength applications of many different types.","title":"Background"},{"location":"#contributors","text":"Irshad A Buchh, Amazon Web Services Mike Rizzo, Amazon Web Services","title":"Contributors"},{"location":"architecture/","text":"Architecture \u00b6 Time Estimate: 15 - 20 minutes What is AWS Fargate? AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). Fargate makes it easy for you to focus on building your applications. Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design. With Fargate, you can focus on building and operating your applications whether you are running it with ECS or EKS. You only interact with and pay for your containers, and you avoid the operational overhead of scaling, patching, securing, and managing servers. Fargate ensures that the infrastructure your containers run on is always up-to-date with the required patches. With Fargate, you get out-of-box observability through built-in integrations with other AWS services including Amazon CloudWatch Container Insights. Fargate allows you to gather metrics and logs for monitoring your applications through an extensive selection of third party tools with open interfaces. What is Terraform? Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions. Configuration files describe to Terraform the components needed to run a single application or your entire datacenter. Terraform generates an execution plan describing what it will do to reach the desired state, and then executes it to build the described infrastructure. As the configuration changes, Terraform is able to determine what changed and create incremental execution plans which can be applied. The infrastructure Terraform can manage includes low-level components such as compute instances, storage, and networking, as well as high-level components such as DNS entries, SaaS features, etc.","title":"Module 1 - Architecture"},{"location":"architecture/#architecture","text":"Time Estimate: 15 - 20 minutes What is AWS Fargate? AWS Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). Fargate makes it easy for you to focus on building your applications. Fargate removes the need to provision and manage servers, lets you specify and pay for resources per application, and improves security through application isolation by design. With Fargate, you can focus on building and operating your applications whether you are running it with ECS or EKS. You only interact with and pay for your containers, and you avoid the operational overhead of scaling, patching, securing, and managing servers. Fargate ensures that the infrastructure your containers run on is always up-to-date with the required patches. With Fargate, you get out-of-box observability through built-in integrations with other AWS services including Amazon CloudWatch Container Insights. Fargate allows you to gather metrics and logs for monitoring your applications through an extensive selection of third party tools with open interfaces. What is Terraform? Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions. Configuration files describe to Terraform the components needed to run a single application or your entire datacenter. Terraform generates an execution plan describing what it will do to reach the desired state, and then executes it to build the described infrastructure. As the configuration changes, Terraform is able to determine what changed and create incremental execution plans which can be applied. The infrastructure Terraform can manage includes low-level components such as compute instances, storage, and networking, as well as high-level components such as DNS entries, SaaS features, etc.","title":"Architecture"},{"location":"cleanup/","text":"Tearing down the stack \u00b6 When finished, you can free up resources as follows: cd ../terraform terraform destroy When prompted enter yes to allow the stack termination to proceed. Once complete, note that you will have to manually empty and delete the S3 bucket used by the pipeline.","title":"Module 6 - Cleanup"},{"location":"cleanup/#tearing-down-the-stack","text":"When finished, you can free up resources as follows: cd ../terraform terraform destroy When prompted enter yes to allow the stack termination to proceed. Once complete, note that you will have to manually empty and delete the S3 bucket used by the pipeline.","title":"Tearing down the stack"},{"location":"deploy/","text":"Deploy petclinic application using the pipeline \u00b6 Time Estimate: 15 - 20 minutes What is AWS CodePipeline? AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates. CodePipeline automates the build, test, and deploy phases of your release process every time there is a code change, based on the release model you define. This enables you to rapidly and reliably deliver features and updates. You can easily integrate AWS CodePipeline with third-party services such as GitHub or with your own custom plugin. With AWS CodePipeline, you only pay for what you use. There are no upfront fees or long-term commitments. You will now use git to push the petclinic application through the pipeline. Set up a local git repo for the petclinic application \u00b6 Start by switching to the petclinic directory: cd ../petclinic Set up your git username and email address: git config --global user.name \"Your Name\" git config --global user.email you@example.com Now ceate a local git repo for petclinic as follows: git init git add . git commit -m \"Baseline commit\" Set up the remote CodeCommit repo \u00b6 An AWS CodeCommit repo was built as part of the pipeline you created. You will now set this up as a remote repo for your local petclinic repo. For authentication purposes, you can use the AWS IAM git credential helper to generate git credentials based on your IAM role permissions. Run: git config --global credential.helper '!aws codecommit credential-helper $@' git config --global credential.UseHttpPath true From the output of the Terraform build, note the Terraform output source_repo_clone_url_http . cd ../terraform export tf_source_repo_clone_url_http = $( terraform output source_repo_clone_url_http ) Set this up as a remote for your git repo as follows: cd ../petclinic git remote add origin $tf_source_repo_clone_url_http git remote -v You should see something like: origin https://git-codecommit.eu-west-2.amazonaws.com/v1/repos/petclinic ( fetch ) origin https://git-codecommit.eu-west-2.amazonaws.com/v1/repos/petclinic ( push )","title":"Module 4 - Deploy"},{"location":"deploy/#deploy-petclinic-application-using-the-pipeline","text":"Time Estimate: 15 - 20 minutes What is AWS CodePipeline? AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates. CodePipeline automates the build, test, and deploy phases of your release process every time there is a code change, based on the release model you define. This enables you to rapidly and reliably deliver features and updates. You can easily integrate AWS CodePipeline with third-party services such as GitHub or with your own custom plugin. With AWS CodePipeline, you only pay for what you use. There are no upfront fees or long-term commitments. You will now use git to push the petclinic application through the pipeline.","title":"Deploy petclinic application using the pipeline"},{"location":"deploy/#set-up-a-local-git-repo-for-the-petclinic-application","text":"Start by switching to the petclinic directory: cd ../petclinic Set up your git username and email address: git config --global user.name \"Your Name\" git config --global user.email you@example.com Now ceate a local git repo for petclinic as follows: git init git add . git commit -m \"Baseline commit\"","title":"Set up a local git repo for the petclinic application"},{"location":"deploy/#set-up-the-remote-codecommit-repo","text":"An AWS CodeCommit repo was built as part of the pipeline you created. You will now set this up as a remote repo for your local petclinic repo. For authentication purposes, you can use the AWS IAM git credential helper to generate git credentials based on your IAM role permissions. Run: git config --global credential.helper '!aws codecommit credential-helper $@' git config --global credential.UseHttpPath true From the output of the Terraform build, note the Terraform output source_repo_clone_url_http . cd ../terraform export tf_source_repo_clone_url_http = $( terraform output source_repo_clone_url_http ) Set this up as a remote for your git repo as follows: cd ../petclinic git remote add origin $tf_source_repo_clone_url_http git remote -v You should see something like: origin https://git-codecommit.eu-west-2.amazonaws.com/v1/repos/petclinic ( fetch ) origin https://git-codecommit.eu-west-2.amazonaws.com/v1/repos/petclinic ( push )","title":"Set up the remote CodeCommit repo"},{"location":"infrastructure/","text":"Build the infrastructure and pipeline \u00b6 Time Estimate: 10 - 15 minutes We shall use Terraform to build the above architecture including the AWS CodePipeline. Set up SSM parameter for DB passwd \u00b6 aws ssm put-parameter --name /database/password --value mysqlpassword --type SecureString Edit terraform variables \u00b6 cd terraform Edit terraform.tfvars , leave the aws_profile as \"default\" , and set aws_region to the correct value for your environment. Build \u00b6 Initialise Terraform: terraform init Build the infrastructure and pipeline using terraform: terraform apply Terraform will display an action plan. When asked whether you want to proceed with the actions, enter yes . Wait for Terraform to complete the build before proceeding. It will take few minutes to complete \u201cterraform apply\u201d Explore the stack you have built \u00b6 Once the build is complete, you can explore your environment using the AWS console: - View the RDS database using the Amazon RDS console . View the ALB using the Amazon EC2 console . View the ECS cluster using the Amazon ECS console . View the ECR repo using the Amazon ECR console . View the CodeCommit repo using the AWS CodeCommit console . View the CodeBuild project using the AWS CodeBuild console . View the pipeline using the AWS CodePipeline console . Note that your pipeline starts in a failed state. That is because there is no code to build in the CodeCommit repo! In the next step you will push the petclinic app into the repo to trigger the pipeline.","title":"Module 3 - Build the infrastructure"},{"location":"infrastructure/#build-the-infrastructure-and-pipeline","text":"Time Estimate: 10 - 15 minutes We shall use Terraform to build the above architecture including the AWS CodePipeline.","title":"Build the infrastructure and pipeline"},{"location":"infrastructure/#set-up-ssm-parameter-for-db-passwd","text":"aws ssm put-parameter --name /database/password --value mysqlpassword --type SecureString","title":"Set up SSM parameter for DB passwd"},{"location":"infrastructure/#edit-terraform-variables","text":"cd terraform Edit terraform.tfvars , leave the aws_profile as \"default\" , and set aws_region to the correct value for your environment.","title":"Edit terraform variables"},{"location":"infrastructure/#build","text":"Initialise Terraform: terraform init Build the infrastructure and pipeline using terraform: terraform apply Terraform will display an action plan. When asked whether you want to proceed with the actions, enter yes . Wait for Terraform to complete the build before proceeding. It will take few minutes to complete \u201cterraform apply\u201d","title":"Build"},{"location":"infrastructure/#explore-the-stack-you-have-built","text":"Once the build is complete, you can explore your environment using the AWS console: - View the RDS database using the Amazon RDS console . View the ALB using the Amazon EC2 console . View the ECS cluster using the Amazon ECS console . View the ECR repo using the Amazon ECR console . View the CodeCommit repo using the AWS CodeCommit console . View the CodeBuild project using the AWS CodeBuild console . View the pipeline using the AWS CodePipeline console . Note that your pipeline starts in a failed state. That is because there is no code to build in the CodeCommit repo! In the next step you will push the petclinic app into the repo to trigger the pipeline.","title":"Explore the stack you have built"},{"location":"pipeline/","text":"Trigger the pipeline \u00b6 Time Estimate: 15 - 20 minutes To trigger the pipeline, push the master branch to the remote as follows: git push -u origin master The pipeline will pull the code, build the docker image, push it to ECR, and deploy it to your ECS cluster. This will take a few minutes. You can monitor the pipeline in the AWS CodePipeline console . Test the application \u00b6 From the output of the Terraform build, note the Terraform output alb_address . cd ../terraform export tf_alb_address = $( terraform output alb_address ) echo $tf_alb_address Use this in your browser to access the application. Push a change through the pipeline and re-test \u00b6 The pipeline can now be used to deploy any changes to the application. You can try this out by changing the welcome message as follows: cd ../petclinic vi src/main/resources/messages/messages.properties Change the value for the welcome string, for example, to \"Hello\". Commit the change: git add . git commit -m \"Changed welcome string\" Push the change to trigger pipeline: git push origin master As before, you can use the console to observe the progression of the change through the pipeline. Once done, verify that the application is working with the modified welcome message.","title":"Module 5 - Trigger pipeline"},{"location":"pipeline/#trigger-the-pipeline","text":"Time Estimate: 15 - 20 minutes To trigger the pipeline, push the master branch to the remote as follows: git push -u origin master The pipeline will pull the code, build the docker image, push it to ECR, and deploy it to your ECS cluster. This will take a few minutes. You can monitor the pipeline in the AWS CodePipeline console .","title":"Trigger the pipeline"},{"location":"pipeline/#test-the-application","text":"From the output of the Terraform build, note the Terraform output alb_address . cd ../terraform export tf_alb_address = $( terraform output alb_address ) echo $tf_alb_address Use this in your browser to access the application.","title":"Test the application"},{"location":"pipeline/#push-a-change-through-the-pipeline-and-re-test","text":"The pipeline can now be used to deploy any changes to the application. You can try this out by changing the welcome message as follows: cd ../petclinic vi src/main/resources/messages/messages.properties Change the value for the welcome string, for example, to \"Hello\". Commit the change: git add . git commit -m \"Changed welcome string\" Push the change to trigger pipeline: git push origin master As before, you can use the console to observe the progression of the change through the pipeline. Once done, verify that the application is working with the modified welcome message.","title":"Push a change through the pipeline and re-test"},{"location":"prerequisites/","text":"Prerequisites \u00b6 Before you build the whole infrastructure, including your CI/CD pipeline, you will need to meet the following pre-requisites. AWS account AWS account \u00b6 Ensure you have access to an AWS account, and a set of credentials with Administrator permissions. Note: In a production environment we would recommend locking permissions down to the bare minimum needed to operate the pipeline. Create an AWS Cloud9 environment \u00b6 What is AWS Cloud9? AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don\u2019t need to install files or configure your development machine to start new projects. Since your Cloud9 IDE is cloud-based, you can work on your projects from your office, home, or anywhere using an internet-connected machine. Cloud9 also provides a seamless experience for developing serverless applications enabling you to easily define resources, debug, and switch between local and remote execution of serverless applications. With Cloud9, you can quickly share your development environment with your team, enabling you to pair program and track each other's inputs in real time. Log into the AWS Management Console and search for Cloud9 services in the search bar. Click Cloud9 and create an AWS Cloud9 environment in the us-east-1 region based on Amazon Linux 2. Configure the AWS Cloud9 environment \u00b6 Launch the AWS Cloud9 IDE. Close the Welcome tab and open a new Terminal tab. Create and attach an IAM role for your Cloud9 instance \u00b6 By default, Cloud9 manages temporary IAM credentials for you. Unfortunately these are incomaptible with Terraform. To get around this you need to disable Cloud9 temporary credentials, and create and attach an IAM role for your Cloud9 instance. Follow this deep link to create an IAM role with Administrator access. Confirm that AWS service and EC2 are selected, then click Next to view permissions. Confirm that AdministratorAccess is checked, then click Next: Tags to assign tags. Take the defaults, and click Next: Review to review. Enter workshop-admin for the Name, and click Create role . Follow this deep link to find your Cloud9 EC2 instance Select the instance, then choose Actions / Instance Settings / Modify IAM Role . Note: If you cannot find this menu option, then look under Actions / Security / Modify IAM Role instead. Choose workshop-admin from the IAM Role drop down, and select Apply Return to your workspace and click the gear icon (in top right corner), or click to open a new tab and choose \"Open Preferences\" Select AWS SETTINGS Turn off AWS managed temporary credentials Close the Preferences tab In the Cloud9 terminal pane, execute the command: rm -vf ${ HOME } /.aws/credentials As a final check, use the GetCallerIdentity CLI command to validate that the Cloud9 IDE is using the correct IAM role. aws sts get-caller-identity --query Arn | grep workshop-admin -q && echo \"IAM role valid\" || echo \"IAM role NOT valid\" Upgrade awscli \u00b6 Ensure you are running the latest version of AWS CLI: aws --version pip install awscli --upgrade --user Run aws configure to configure your region. Leave all the other fields blank. You should have something like: admin:~/environment $ aws configure AWS Access Key ID [None]: AWS Secret Access Key [None]: Default region name [None]: us-east-1 Default output format [None]: Install Terraform \u00b6 Download and install Terraform: wget https://releases.hashicorp.com/terraform/0.13.4/terraform_0.13.4_linux_amd64.zip unzip terraform_0.13.4_linux_amd64.zip sudo mv terraform /usr/local/bin/ export PATH = $PATH :/usr/local/bin/terraform Verify that you can run Terraform: terraform version Install workshop files \u00b6 You will need to import the workshop files into your Cloud9 environment: wget https://github.com/aws-samples/aws-ecs-cicd-terraform/archive/master.zip unzip master.zip cd aws-ecs-cicd-terraform-master","title":"Module 2 - Prerequisites"},{"location":"prerequisites/#prerequisites","text":"Before you build the whole infrastructure, including your CI/CD pipeline, you will need to meet the following pre-requisites. AWS account","title":"Prerequisites"},{"location":"prerequisites/#aws-account","text":"Ensure you have access to an AWS account, and a set of credentials with Administrator permissions. Note: In a production environment we would recommend locking permissions down to the bare minimum needed to operate the pipeline.","title":"AWS account"},{"location":"prerequisites/#create-an-aws-cloud9-environment","text":"What is AWS Cloud9? AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don\u2019t need to install files or configure your development machine to start new projects. Since your Cloud9 IDE is cloud-based, you can work on your projects from your office, home, or anywhere using an internet-connected machine. Cloud9 also provides a seamless experience for developing serverless applications enabling you to easily define resources, debug, and switch between local and remote execution of serverless applications. With Cloud9, you can quickly share your development environment with your team, enabling you to pair program and track each other's inputs in real time. Log into the AWS Management Console and search for Cloud9 services in the search bar. Click Cloud9 and create an AWS Cloud9 environment in the us-east-1 region based on Amazon Linux 2.","title":"Create an AWS Cloud9 environment"},{"location":"prerequisites/#configure-the-aws-cloud9-environment","text":"Launch the AWS Cloud9 IDE. Close the Welcome tab and open a new Terminal tab.","title":"Configure the AWS Cloud9 environment"},{"location":"prerequisites/#create-and-attach-an-iam-role-for-your-cloud9-instance","text":"By default, Cloud9 manages temporary IAM credentials for you. Unfortunately these are incomaptible with Terraform. To get around this you need to disable Cloud9 temporary credentials, and create and attach an IAM role for your Cloud9 instance. Follow this deep link to create an IAM role with Administrator access. Confirm that AWS service and EC2 are selected, then click Next to view permissions. Confirm that AdministratorAccess is checked, then click Next: Tags to assign tags. Take the defaults, and click Next: Review to review. Enter workshop-admin for the Name, and click Create role . Follow this deep link to find your Cloud9 EC2 instance Select the instance, then choose Actions / Instance Settings / Modify IAM Role . Note: If you cannot find this menu option, then look under Actions / Security / Modify IAM Role instead. Choose workshop-admin from the IAM Role drop down, and select Apply Return to your workspace and click the gear icon (in top right corner), or click to open a new tab and choose \"Open Preferences\" Select AWS SETTINGS Turn off AWS managed temporary credentials Close the Preferences tab In the Cloud9 terminal pane, execute the command: rm -vf ${ HOME } /.aws/credentials As a final check, use the GetCallerIdentity CLI command to validate that the Cloud9 IDE is using the correct IAM role. aws sts get-caller-identity --query Arn | grep workshop-admin -q && echo \"IAM role valid\" || echo \"IAM role NOT valid\"","title":"Create and attach an IAM role for your Cloud9 instance"},{"location":"prerequisites/#upgrade-awscli","text":"Ensure you are running the latest version of AWS CLI: aws --version pip install awscli --upgrade --user Run aws configure to configure your region. Leave all the other fields blank. You should have something like: admin:~/environment $ aws configure AWS Access Key ID [None]: AWS Secret Access Key [None]: Default region name [None]: us-east-1 Default output format [None]:","title":"Upgrade awscli"},{"location":"prerequisites/#install-terraform","text":"Download and install Terraform: wget https://releases.hashicorp.com/terraform/0.13.4/terraform_0.13.4_linux_amd64.zip unzip terraform_0.13.4_linux_amd64.zip sudo mv terraform /usr/local/bin/ export PATH = $PATH :/usr/local/bin/terraform Verify that you can run Terraform: terraform version","title":"Install Terraform"},{"location":"prerequisites/#install-workshop-files","text":"You will need to import the workshop files into your Cloud9 environment: wget https://github.com/aws-samples/aws-ecs-cicd-terraform/archive/master.zip unzip master.zip cd aws-ecs-cicd-terraform-master","title":"Install workshop files"}]}